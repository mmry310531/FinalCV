{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5967f7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imutils in /Users/caichengen/opt/anaconda3/lib/python3.9/site-packages (0.5.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install imutils\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26c3d5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import argparse\n",
    "import ntpath\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import imutils\n",
    "from imutils.video import WebcamVideoStream\n",
    "from imutils import face_utils\n",
    "from Detect_Acne import *\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdff22d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to detect face feature\n",
    "import dlib\n",
    "predictor_model = 'shape_predictor_68_face_landmarks.dat'\n",
    "detector = dlib.get_frontal_face_detector()# dlib人脸检测器\n",
    "predictor = dlib.shape_predictor(predictor_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd8ccc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFiles(path):\n",
    "    img = cv2.imread(path)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15d9b1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "detectors = {\n",
    "    \"eye\": os.path.sep.join([ntpath.dirname(cv2.__file__), 'data', 'haarcascade_eye.xml']),\n",
    "    \"face\": os.path.sep.join([ntpath.dirname(cv2.__file__), 'data', 'haarcascade_frontalface_default.xml'])\n",
    "}\n",
    "def detect(gray, part=\"face\"):\n",
    "    \n",
    "    detector = cv2.CascadeClassifier(detectors[part])\n",
    "    rects = detector.detectMultiScale(gray, scaleFactor=2, minNeighbors=5, minSize=(15, 15),\n",
    "                                      flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    return rects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "511e5eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "heightResize = 480\n",
    "framesSkipping = 2\n",
    "\n",
    "cameraObject = cv2.VideoCapture(0)\n",
    "ret, image = cameraObject.read()\n",
    "height = image.shape[0]\n",
    "\n",
    "frame_resize_scale = float(height)/heightResize\n",
    "modelPath = \"shape_predictor_68_face_landmarks.dat\"\n",
    "\n",
    "faceDetector = dlib.get_frontal_face_detector()\n",
    "shapePredictor = dlib.shape_predictor(modelPath)\n",
    "\n",
    "\n",
    "def Recording():\n",
    "    count = 0\n",
    "    # open webcam\n",
    "    vs = WebcamVideoStream().start()\n",
    "    start = time.time()\n",
    "    fps = vs.stream.get(cv2.CAP_PROP_FPS)\n",
    "    print(\"Frames per second using cv2.CAP_PROP_FPS : {0}\".format(fps))\n",
    "\n",
    "    while True:\n",
    "        # turn to gray image to detect face\n",
    "        frame = vs.read()\n",
    "        img = frame.copy()\n",
    "        img = imutils.resize(img, width=600)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        \n",
    "        if (count % framesSkipping == 0):\n",
    "            faces = faceDetector(img,0)\n",
    "        for face in faces:\n",
    "#             newRectValues = dlib.rectangle(int(face.left() * frame_resize_scale),\n",
    "#                                int(face.top() * frame_resize_scale),\n",
    "#                                int(face.right() * frame_resize_scale),\n",
    "#                                int(face.bottom() * frame_resize_scale))\n",
    "            predictor = shapePredictor(img, face)\n",
    "            landmarks = np.matrix([[p.x, p.y] for p in predictor.parts()])\n",
    "            faceMask = get_image_hull_mask(img, landmarks)\n",
    "        img = cv2.bitwise_and(faceMask, img)\n",
    "        cv2.imshow(\"Frame\", img)\n",
    "\n",
    "        count = count + 1\n",
    "        # calculate framePerSecond at an interval of 100 frames\n",
    "        if (count == 100):\n",
    "            count = 0\n",
    "        \n",
    "        # 判斷是否案下\"q\"；跳離迴圈\n",
    "        key = cv2.waitKey(1) & 0xff\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "    #  清除畫面與結束WebCam\n",
    "    cv2.destroyAllWindows()\n",
    "    vs.stop()\n",
    "\n",
    "\n",
    "# Recording()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cec2cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2Gray(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return img, gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43128b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImage(img):\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88da710b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetFaceMask(img):\n",
    "    img, Gimg = img2Gray(img)\n",
    "    rects = detect(Gimg) # return multi-face\n",
    "    \n",
    "    # Face mask, cut out of face region\n",
    "    Facemask = np.zeros_like(img)\n",
    "    (y, x, w, h) = rects[0].astype(\"int\")\n",
    "    Facemask = cv2.rectangle(Facemask, (y,x), (y + w, x + h), (255,255,255), -1)\n",
    "    \n",
    "    return Facemask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18b25fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skinDetection(img):\n",
    "    img_HSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    HSV_mask = cv2.inRange(img_HSV, (0, 15, 0), (17,170,255)) \n",
    "    HSV_mask = cv2.morphologyEx(HSV_mask, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))\n",
    "\n",
    "    #converting from gbr to YCbCr color space\n",
    "    img_YCrCb = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "    #skin color range for hsv color space \n",
    "    YCrCb_mask = cv2.inRange(img_YCrCb, (0, 135, 85), (255,180,135)) \n",
    "    YCrCb_mask = cv2.morphologyEx(YCrCb_mask, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))\n",
    "\n",
    "    #merge skin detection (YCbCr and hsv)\n",
    "    global_mask=cv2.bitwise_and(YCrCb_mask,HSV_mask)\n",
    "    global_mask=cv2.medianBlur(global_mask,3)\n",
    "    global_mask = cv2.morphologyEx(global_mask, cv2.MORPH_OPEN, np.ones((4,4), np.uint8))\n",
    "\n",
    "\n",
    "    HSV_result = cv2.bitwise_not(HSV_mask)\n",
    "    YCrCb_result = cv2.bitwise_not(YCrCb_mask)\n",
    "    global_result=cv2.bitwise_not(global_mask)\n",
    "    \n",
    "    return global_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f46414b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSkinMask(img):\n",
    "    # find skin region, 0 is skin, otherwise is 1\n",
    "    SkinImage = skinDetection(img)\n",
    "    skinMask = np.zeros_like(img)\n",
    "    skinMask[SkinImage[:,:] == 0] = (255,255,255)\n",
    "    skinMask[SkinImage[:,:] == 1] = (0, 0, 0)\n",
    "    \n",
    "    return skinMask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "239b4f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_landmarks(Gimg):\n",
    "\n",
    "    predictor_model = 'shape_predictor_68_face_landmarks.dat'\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    \n",
    "    StartTime = time.time() # start time\n",
    "    predictor = dlib.shape_predictor(predictor_model)\n",
    "    \n",
    "    print(time.time() - StartTime) # end time\n",
    "    \n",
    "    rects = detector(Gimg, 0)\n",
    "    face = rects[0]\n",
    "    shape = predictor(Gimg, face)\n",
    "    shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "    \n",
    "    landmarks = np.matrix([[p.x, p.y] for p in predictor(Gimg, face).parts()])\n",
    "    return landmarks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0834d179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyclipper in /Users/caichengen/opt/anaconda3/lib/python3.9/site-packages (1.3.0.post2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyclipper\n",
    "import pyclipper\n",
    "\n",
    "def perimeter(poly):\n",
    "    p = 0\n",
    "    nums = poly.shape[0]\n",
    "    for i in range(nums):\n",
    "        p += abs(np.linalg.norm(poly[i % nums] - poly[(i + 1) % nums]))\n",
    "    return p\n",
    "\n",
    "def proportional_zoom_contour(contour, ratio):\n",
    "    \"\"\"\n",
    "    多边形轮廓点按照比例进行缩放\n",
    "    :param contour: 一个图形的轮廓格式[[[x1, x2]],...],shape是(-1, 1, 2)\n",
    "    :param ratio: 缩放的比例，如果大于1是放大小于1是缩小\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    poly = contour[:, :]\n",
    "    area_poly = abs(pyclipper.Area(poly))\n",
    "    perimeter_poly = perimeter(poly)\n",
    "    poly_s = []\n",
    "    pco = pyclipper.PyclipperOffset()\n",
    "    pco.MiterLimit = 10\n",
    "    if perimeter_poly:\n",
    "        d = area_poly * (1 - ratio * ratio) / perimeter_poly\n",
    "        pco.AddPath(poly, pyclipper.JT_MITER, pyclipper.ET_CLOSEDPOLYGON)\n",
    "        poly_s = pco.Execute(-d)\n",
    "    poly_s = np.array(poly_s).reshape(-1, 1, 2).astype(int)\n",
    "\n",
    "    return poly_s\n",
    "\n",
    "def get_image_hull_mask(img, image_landmarks, ie_polys=None):\n",
    "    # get the mask of the image\n",
    "    if image_landmarks.shape[0] != 68:\n",
    "        raise Exception(\n",
    "            'get_image_hull_mask works only with 68 landmarks')\n",
    "    int_lmrks = np.array(image_landmarks, dtype=np.int)\n",
    "\n",
    "    #hull_mask = np.zeros(image_shape[0:2]+(1,), dtype=np.float32)\n",
    "    hull_mask = np.zeros_like(img)\n",
    "\n",
    "    cv2.fillConvexPoly(hull_mask, cv2.convexHull(\n",
    "        np.concatenate((int_lmrks[0:9],\n",
    "                        int_lmrks[17:18]))), (255,255, 255))\n",
    "\n",
    "    cv2.fillConvexPoly(hull_mask, cv2.convexHull(\n",
    "        np.concatenate((int_lmrks[8:17],\n",
    "                        int_lmrks[26:27]))), (255,255, 255))\n",
    "\n",
    "    cv2.fillConvexPoly(hull_mask, cv2.convexHull(\n",
    "        np.concatenate((int_lmrks[17:20],\n",
    "                        int_lmrks[8:9]))), (255,255, 255))\n",
    "\n",
    "    cv2.fillConvexPoly(hull_mask, cv2.convexHull(\n",
    "        np.concatenate((int_lmrks[24:27],\n",
    "                        int_lmrks[8:9]))), (255,255, 255))\n",
    "\n",
    "    cv2.fillConvexPoly(hull_mask, cv2.convexHull(\n",
    "        np.concatenate((int_lmrks[19:25],\n",
    "                        int_lmrks[8:9],\n",
    "                        ))), (255,255, 255))\n",
    "\n",
    "    cv2.fillConvexPoly(hull_mask, cv2.convexHull(\n",
    "        np.concatenate((int_lmrks[17:22],\n",
    "                        int_lmrks[27:28],\n",
    "                        int_lmrks[31:36],\n",
    "                        int_lmrks[8:9]\n",
    "                        ))), (255,255, 255))\n",
    "\n",
    "    cv2.fillConvexPoly(hull_mask, cv2.convexHull(\n",
    "        np.concatenate((int_lmrks[22:27],\n",
    "                        int_lmrks[27:28],\n",
    "                        int_lmrks[31:36],\n",
    "                        int_lmrks[8:9]\n",
    "                        ))), (255,255, 255))\n",
    "\n",
    "    nose = proportional_zoom_contour(int_lmrks[27:36], 1.2)\n",
    "    l_eyes = proportional_zoom_contour(int_lmrks[36:42], 1.8)\n",
    "    r_eyes = proportional_zoom_contour(int_lmrks[42:48], 1.8)\n",
    "    mouse = proportional_zoom_contour(int_lmrks[48:60], 1.3)\n",
    "    \n",
    "    l_brow = proportional_zoom_contour(int_lmrks[17:22], 1.4)\n",
    "    r_brow = proportional_zoom_contour(int_lmrks[22:27], 1.4)\n",
    "    \n",
    "    \n",
    "    #face\n",
    "    for i in range(17-3):\n",
    "        cv2.fillConvexPoly(\n",
    "            hull_mask, int_lmrks[i:i+3], (0,0, 0))\n",
    "        \n",
    "    # nose\n",
    "    cv2.fillConvexPoly(\n",
    "        hull_mask, cv2.convexHull(nose), (0,0, 0))\n",
    "    # left eyes\n",
    "    cv2.fillConvexPoly(\n",
    "        hull_mask, cv2.convexHull(l_eyes), (0,0, 0))\n",
    "    # right eyes\n",
    "    cv2.fillConvexPoly(\n",
    "        hull_mask, cv2.convexHull(r_eyes), (0,0, 0))\n",
    "    # mouse \n",
    "    cv2.fillConvexPoly(\n",
    "        hull_mask, cv2.convexHull(mouse), (0,0, 0))\n",
    "    \n",
    "    #brow\n",
    "    cv2.fillConvexPoly(\n",
    "        hull_mask, cv2.convexHull(l_brow), (0,0, 0))\n",
    "    cv2.fillConvexPoly(\n",
    "        hull_mask, cv2.convexHull(r_brow), (0,0, 0))\n",
    "    \n",
    "\n",
    "    return hull_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1944405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.545494794845581\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    #Read Image\n",
    "    Origin_img = cv2.imread('data/acne_face.jpeg')\n",
    "    img = Origin_img.copy()\n",
    "#     img = imutils.resize(img, width=300)\n",
    "    img,Gimg = img2Gray(img)\n",
    "    \n",
    "#     # Method 1 to get face (Skin Detection and Face Detection(Harr))\n",
    "#     skinMask = GetSkinMask(img)\n",
    "#     faceMask = GetFaceMask(img)\n",
    "#     # combine two mask\n",
    "#     Face_Skin_Mask = cv2.bitwise_and(skinMask, faceMask)\n",
    "#     img = cv2.bitwise_and(Face_Skin_Mask, img)\n",
    "#     # can't cut out only face in result\n",
    "\n",
    "    # Method 2 to get face (Use Dlib)\n",
    "    SkinMask = GetSkinMask(img)\n",
    "    landmarks = get_landmarks(Gimg)\n",
    "    faceMask = get_image_hull_mask(img, landmarks)\n",
    "    img = cv2.bitwise_and(faceMask, img)\n",
    "    img = cv2.bitwise_and(SkinMask, img)\n",
    "    # not a good method, which cost 1.55 sec\n",
    "\n",
    "    \n",
    "#     img = cv2.imread('./data/acne.jpg')\n",
    "    ad = Acne_Dector(img)\n",
    "    ad.run(method =1, debug=False)\n",
    "    img = cv2.inpaint(Origin_img, ad.mask, 3, cv2.INPAINT_TELEA)\n",
    "    cv2.imwrite(\"Result_acne_face.jpg\", img)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc81e5a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d52848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240677c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b2e4f1c965dd030247e241f2d73e52f9417b40a34049ea27164b2703d5e6cad1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
